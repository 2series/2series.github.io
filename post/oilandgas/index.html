<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.2.5">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Rihad Variawa">

  
  
  
    
  
  <meta name="description" content="The key to success is consistently making good decisions, and the key to making good decisions is having good information. This belief is the main impetus behind the explosive interest in Big Data. We all know intuitively that access to more data presents the potential to obtain better data and therefore better decisions, yet more data in-and-of itself does not necessarily result in better decisions. We must also sift through the data and discover the good information.">

  
  <link rel="alternate" hreflang="en-us" href="../../post/oilandgas/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Playfair+Display:400,700|Fauna+One">
  

  <link rel="stylesheet" href="../../styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-132898309-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="../../site.webmanifest">
  <link rel="icon" type="image/png" href="../../img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="../../img/icon-192.png">

  <link rel="canonical" href="../../post/oilandgas/">

  
  
  
  
    
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@2series_cs">
  <meta property="twitter:creator" content="@2series_cs">
  
  <meta property="og:site_name" content="Rihad Variawa">
  <meta property="og:url" content="/post/oilandgas/">
  <meta property="og:title" content="Oil and Gas Asset Optimization | Rihad Variawa">
  <meta property="og:description" content="The key to success is consistently making good decisions, and the key to making good decisions is having good information. This belief is the main impetus behind the explosive interest in Big Data. We all know intuitively that access to more data presents the potential to obtain better data and therefore better decisions, yet more data in-and-of itself does not necessarily result in better decisions. We must also sift through the data and discover the good information."><meta property="og:image" content="/img/ship.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-03-10T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2020-03-10T00:00:00&#43;00:00">
  

  

  

  <title>Oil and Gas Asset Optimization | Rihad Variawa</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="../../">Rihad Variawa</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#posts">
            
            <span>Blog Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="../../#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Oil and Gas Asset Optimization</h1>

  

  
    



<meta content="2020-03-10 00:00:00 &#43;0000 UTC" itemprop="datePublished">
<meta content="2020-03-10 00:00:00 &#43;0000 UTC" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Mar 10, 2020</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    8 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="../../post/oilandgas/#disqus_thread"></a>
  

  

  
    

  

</div>

    
















  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<p><img src="https://r-variawa.rstudio.cloud/d51019dc107e470cb38611324883b9a0/file_show?path=%2Fcloud%2Fproject%2Fstatic%2Fimg%2Flg.png" alt="lg" /></p>

<p>The key to success is consistently making good decisions, and the key to making good decisions is having good information. This belief is the main impetus behind the explosive interest in Big Data. We all know intuitively that access to more data presents the potential to obtain better data and therefore better decisions, yet more data in-and-of itself does not necessarily result in better decisions. We must also sift through the data and discover the good information. Doing so effectively is especially important in capital intensive industries.</p>

<p>The oil and gas industry is an asset-intensive business with capital assets ranging from drilling rigs, offshore platforms and wells to pipelines, LNG terminals, and refineries. These assets are costly to design, build, operate, and maintain. Analysis of the financial statements of the five super-majors (BP, ConocoPhillips, ExxonMobil, Shell, Total) shows that plant, property and equipment on average accounts for 51% of total assets. Effectively managing these assets requires oil and gas industry to leverage advanced machine learning and analytics on extreme large volumes of data, in batch and real-time. Apache Spark is ideal for handling this type of workload and Databricks is the ideal platform for building Apache Spark solutions.</p>

<p>In this blog we will solve a typical problem in the oil and gas industry – asset optimization. We will demonstrate a solution with three components:</p>

<ul>
<li>AWS Kinesis to stream the real time data;</li>
<li>AWS RDS to store our historical data;</li>
<li>Malastare AI to process the data from RDS and Kinesis to determine the optimal asset levels.</li>
</ul>

<h2 id="background-to-asset-optimization">Background To Asset Optimization</h2>

<p><em>Asset</em> refers to tangible goods used by the business to generate revenue – raw material, equipment, etc. Business operations consume assets (i.e., wearing down a piece of equipment), and must replenish them to continue revenue generation. The estimation of timing and quantity of the replenishment is the heart of asset optimization because errors are costly: revenue stops flowing if the business runs out of raw materials, while excess stockpiles incur holding costs. Ideally, asset optimization accurately determines the correct asset levels based on analytics of near real-time consumption data. The goal is to precisely estimate how much stock will be used in the time it takes for an order to arrive with pinpoint accuracy.</p>

<h2 id="asset-optimization-example">Asset Optimization Example</h2>

<p>In the capital intensive oil and gas industry, every single hour of inefficient asset operation or unscheduled downtime cost millions. In the current Internet-of-Things (IoT) Big Data era, asset optimization focuses on continuously monitoring key operating characteristics of assets and applying advanced machine learning to maximize asset performance and minimize unplanned outages. That is where Big Data and advance analytics come in. The remainder of the blog we will look at a power generation plant example, where we monitor asset meters in real-time and model key measurements to determine whether assets are functioning optimally.</p>

<p>We model this by fitting a distribution to the limited lead time data we have and then sampling from that distribution. Fitting the distribution is the slowest part as it must be done numerically using Markov chain Monte Carlo (MCMC), for our asset this requires a loop of 100,000 iterations which cannot be done in parallel. This whole process must be done for each material in the data set, depending on the plant this can be 3,000+. Each material can be analyzed independently and in parallel.</p>

<h2 id="streaming-sensor-reading-with-aws-kinesis">Streaming Sensor Reading With AWS Kinesis</h2>

<h3 id="step-1-import-the-kinesis-libaries">Step 1: Import the Kinesis Libaries</h3>

<p>This example assumes a Spark 2.0.1 (Scala 2.11). In this particular notebook, make sure you have attached Maven dependencies spark-streaming-kinesis for same version of Spark as your cluster and corresponding kinesis-client library.</p>

<h3 id="step-2-configure-kinesis-stream">Step 2: Configure Kinesis Stream</h3>

<pre><code class="language-R">// === Configuration to control the flow of the application ===
val stopActiveContext = true     
// &quot;true&quot;  = stop if any existing StreamingContext is running;              
// &quot;false&quot; = don't stop, and let it run undisturbed, but your latest code may not be used

// === Configurations for Spark Streaming ===
val batchIntervalSeconds = 10 
val eventsPerSecond = 1000    // For the dummy source

// Verify that the attached Spark cluster is 1.4.0+
require(sc.version.replace(&quot;.&quot;, &quot;&quot;).toInt &gt;= 140)
</code></pre>

<h3 id="step-3-defining-the-function-that-consumes-the-stream">Step 3: Defining the function that consumes the Stream</h3>

<p>This function consumes a dummy stream that we have created for the sake of demonstrating Kinesis. The data that we use latter is staged as JSON files.</p>

<pre><code class="language-R">import scala.util.Random
import org.apache.spark.streaming.receiver._

class DummySource(ratePerSec: Int) extends Receiver[String](StorageLevel.MEMORY_AND_DISK_2) {
  def onStart() {
    // Start the thread that receives data over a connection
    new Thread(&quot;Dummy Source&quot;) {
      override def run() { receive() }
    }.start()
  }

  def onStop() {
   // There is nothing much to do as the thread calling receive()
   // is designed to stop by itself isStopped() returns false
  }

  /** Create a socket connection and receive data until receiver is stopped */
  private def receive() {
    while(!isStopped()) {      
      store(&quot;I am a dummy source &quot; + Random.nextInt(10))
      Thread.sleep((1000.toDouble / ratePerSec).toInt)
    }
  }
}
</code></pre>

<h2 id="storing-historical-data-in-aws-rds">Storing Historical Data In AWS RDS</h2>

<p>Let’s connect to a relational database to look at our master data and choose the Power Plant we want to create our first model for. We will be using Redshift as our database but the steps are essentially the same for connecting to any database. For our simulation, Redshift is where master data regarding the assets is stored. In the real world, this data could be stored in any relational database.</p>

<h3 id="step-1-create-a-dataframe-from-an-entire-redshift-table">Step 1: Create a DataFrame from an entire Redshift table</h3>

<pre><code class="language-R">val mstr_plant_from_redshift = sqlContext.read
  .format(&quot;com.malastareAI.spark.redshift&quot;)
  .option(&quot;url&quot;, jdbcUrl) // JDBC URL that we configured earlier
  .option(&quot;tempdir&quot;, tempDir) // temporary bucket that we created earlier
  .option(&quot;dbtable&quot;, &quot;mstr_plant_rsi&quot;) // name of the table in Redshift
  .load()
</code></pre>

<h3 id="step-2-create-a-temporary-view">Step 2: Create a Temporary View</h3>

<pre><code class="language-R">mstr_plant_from_redshift.createOrReplaceTempView(&quot;tmp_mstr_plant1&quot;)
</code></pre>

<h3 id="step-3-select-and-view-list-of-power-plants">Step 3: Select and View list of Power Plants</h3>

<pre><code class="language-R">sql select * from tmp_mstr_plant1
</code></pre>

<p>We can use ANSI SQL to explore our master data and decide what asset we would like to use for our initial analysis.</p>

<h2 id="monitoring-and-anomaly-detection">Monitoring And Anomaly Detection</h2>

<h3 id="step-1-let-s-load-our-data">Step 1: Let&rsquo;s load our data</h3>

<p>Source measurement data from staged JSON data. In the real world, this would be sourced directly from Kinesis or another streaming technology as I showed with the dummy example above.</p>

<p>Load staged data from JSON files:</p>

<pre><code class="language-R">mounts_list = [
{'bucket':'databricks-corp-training/structured_streaming/devices', 'mount_folder':'/mnt/sdevices'}
]

for mount_point in mounts_list:
  bucket = mount_point['bucket']
  mount_folder = mount_point['mount_folder']
  try:
    dbutils.fs.ls(mount_folder)
    dbutils.fs.unmount(mount_folder)
  except:
    pass
  finally: #If MOUNT_FOLDER does not exist
    dbutils.fs.mount(&quot;s3a://&quot;+ ACCESSY_KEY_ID + &quot;:&quot; + SECRET_ACCESS_KEY + &quot;@&quot; + bucket,mount_folder)
</code></pre>

<p>Define a schema for the JSON Device data so that Spark doesn’t have to infer it:</p>

<pre><code class="language-R">import org.apache.spark.sql.types._
//fetch the JSON device information uploaded into the Filestore
val jsonFile = &quot;dbfs:/mnt/sdevices/&quot;
val jsonSchema = new StructType()
        .add(&quot;battery_level&quot;, LongType)
        .add(&quot;c02_level&quot;, LongType)
        .add(&quot;cca3&quot;,StringType)
        .add(&quot;cn&quot;, StringType)
        .add(&quot;device_id&quot;, LongType)
        .add(&quot;device_type&quot;, StringType)
        .add(&quot;signal&quot;, LongType)
        .add(&quot;ip&quot;, StringType)
        .add(&quot;temp&quot;, LongType)
        .add(&quot;timestamp&quot;, TimestampType)
</code></pre>

<p>Read the JSON files from the mounted directory using the specified schema. Providing the schema avoids Spark to infer Schema, hence making the read operation faster:</p>

<pre><code class="language-R">val devicesDF = spark
                  .read
                  .schema(jsonSchema)
                  .json(jsonFile)
</code></pre>

<h3 id="step-2-explore-our-data">Step 2: Explore our data</h3>

<pre><code class="language-R">disolay(devicesDF)
</code></pre>

<h3 id="step-3-visualize-our-data">Step 3: Visualize our data</h3>

<pre><code class="language-R">// import some SQL aggregate and windowing function
import org.apache.spark.sql.functions._

val staticCountsDF = devicesDF
    .select(&quot;device_type&quot;, &quot;battery_level&quot;)
    .where (&quot;signal &lt;= 15&quot;)
    .groupBy($&quot;device_type&quot;, $&quot;battery_level&quot;)
    .count()
// Let's register the DataFrame as table 'static_device_counts'
staticCountsDF.createOrReplaceTempView(&quot;static_device_counts&quot;)

display(staticCountsDF)
</code></pre>

<p><img src="https://r-variawa.rstudio.cloud/d51019dc107e470cb38611324883b9a0/file_show?path=%2Fcloud%2Fproject%2Fstatic%2Fimg%2Fsparkjobs.png" alt="spark jobs" /></p>

<h3 id="step-4-stream-processing">Step 4: Stream Processing</h3>

<p>Read the stream</p>

<pre><code class="language-R">val streamingSignalsCountsDF = streamingDevicesDF
    .select(&quot;device_type&quot;, &quot;battery_level&quot;)
    .where (&quot;signal &lt;= 15&quot;)
    .groupBy($&quot;device_type&quot;, $&quot;battery_level&quot;)
    .count()
// Is this DF actually a streaming DF?
streamingSignalsCountsDF.isStreaming
</code></pre>

<h3 id="step-5-monitor-the-stream-in-real-time">Step 5: Monitor the Stream in real time</h3>

<pre><code class="language-R">display(streamingSignalsCountsDF)
</code></pre>

<p><img src="https://r-variawa.rstudio.cloud/d51019dc107e470cb38611324883b9a0/file_show?path=%2Fcloud%2Fproject%2Fstatic%2Fimg%2Fstatusactive.png" alt="status active" /></p>

<h3 id="step-6-model-the-data-and-optimize-the-asset">Step 6: Model the data and optimize the asset</h3>

<p>We have staged some sensor data as a csv. In the real world, you would read this off the stream as I have shown above. Let&rsquo;s create a temporary table we will use in our analysis.</p>

<pre><code class="language-R">sqlContext.read.format(&quot;csv&quot;)
  .option(&quot;header&quot;, &quot;true&quot;)
  .option(&quot;delimiter&quot;, &quot;\t&quot;)
  .option(&quot;inferSchema&quot;, &quot;true&quot;)
  .load(&quot;dbfs:/databricks-datasets/power-plant/data/&quot;)
  .createOrReplaceTempView(&quot;power_plant_sf&quot;)
</code></pre>

<p>The next step is to prepare the data. Since all of this data is numeric and consistent this is a simple task for us today. We will need to convert the predictor features from columns to Feature Vectors using the <em>org.apache.spark.ml.feature.VectorAssembler</em>. The <em>VectorAssembler</em> will be the first step in building our ML pipeline.</p>

<pre><code class="language-R">import org.apache.spark.ml.feature.VectorAssembler
val dataset = sqlContext.table(&quot;power_plant_sf&quot;)
val vectorizer =  new VectorAssembler()
  .setInputCols(Array(&quot;AT&quot;, &quot;V&quot;, &quot;AP&quot;, &quot;RH&quot;))
  .setOutputCol(&quot;features&quot;)
</code></pre>

<p>The linear correlation is not as strong between Exhaust Vacuum Speed and Power Output but there is some resemblance of a pattern. Now let’s model our data to predict what the power output will be given a set of sensor readings.</p>

<pre><code class="language-R">// First let's hold out 20% of our data for testing and leave 80% for training
var Array(split20, split80) = dataset.randomSplit(Array(0.20, 0.80), 1800009193L)

// Let's cache these datasets for performance
val testSet = split20.cache()
testSet.count()
val trainingSet = split80.cache()
trainingSet.count()

// ***** LINEAR REGRESSION MODEL ****

import org.apache.spark.ml.regression.LinearRegression
import org.apache.spark.ml.regression.LinearRegressionModel
import org.apache.spark.ml.Pipeline

// Let's initialize our linear regression learner
val lr = new LinearRegression()

// Now we set the parameters for the method
lr.setPredictionCol(&quot;Predicted_PE&quot;)
  .setLabelCol(&quot;PE&quot;)
  .setMaxIter(100)
  .setRegParam(0.1)
// We will use the new spark.ml pipeline API. If you have worked with scikit-learn this will be very familiar.
val lrPipeline = new Pipeline()
lrPipeline.setStages(Array(vectorizer, lr))
// Let's first train on the entire dataset to see what we get
val lrModel = lrPipeline.fit(trainingSet)

val predictionsAndLabels = lrModel.transform(testSet)

display(predictionsAndLabels.select(&quot;AT&quot;, &quot;V&quot;, &quot;AP&quot;, &quot;RH&quot;, &quot;PE&quot;, &quot;Predicted_PE&quot;))

</code></pre>

<p><img src="https://r-variawa.rstudio.cloud/d51019dc107e470cb38611324883b9a0/file_show?path=%2Fcloud%2Fproject%2Fstatic%2Fimg%2F1000rows.png" alt="1000 rows" /></p>

<p>Now that we have real predictions we can use an evaluation metric such as RMSE (Root Mean Squared Error) to validate our regression model. The lower the RMSE, the better our model.</p>

<pre><code class="language-R">//Now let's compute some evaluation metrics against our test dataset

import org.apache.spark.mllib.evaluation.RegressionMetrics 

val metrics = new RegressionMetrics(predictionsAndLabels.select(&quot;Predicted_PE&quot;, &quot;PE&quot;).rdd.map(r =&gt; (r(0).asInstanceOf[Double], r(1).asInstanceOf[Double])))

val rmse = metrics.rootMeanSquaredError
val explainedVariance = metrics.explainedVariance
val r2 = metrics.r2

// First we calculate the residual error and divide it by the RMSE
predictionsAndLabels.selectExpr(&quot;PE&quot;, &quot;Predicted_PE&quot;, &quot;PE - Predicted_PE Residual_Error&quot;, s&quot;&quot;&quot; (PE - Predicted_PE) / $rmse Within_RSME&quot;&quot;&quot;).createOrReplaceTempView(&quot;Power_Plant_RMSE_Evaluation&quot;)

</code></pre>

<p>Now we can display the RMSE as a Histogram. Clearly this shows that the RMSE is centered around 0 with the vast majority of the error within 2 RMSEs.</p>

<pre><code class="language-R">SELECT Within_RSME  from Power_Plant_RMSE_Evaluation

</code></pre>

<p><img src="https://r-variawa.rstudio.cloud/d51019dc107e470cb38611324883b9a0/file_show?path=%2Fcloud%2Fproject%2Fstatic%2Fimg%2FwithinRMSE.png" alt="within RMSE" /></p>

<p>As you can see the Predictions are very close to the real data points. Now we can predict the optimal operating parameters for this plant and apply this model to other plants in real-time.</p>

<h2 id="this-just-one-of-many-examples-of-how-malastare-ai-can-seamlessly-work-with-other-aws-components-to-deliver-advanced-solutions">This just one of many examples of how Malastare AI can seamlessly work with other AWS components to deliver advanced solutions.</h2>

    </div>

    


    
      






  







<div class="media author-card" itemscope itemtype="http://schema.org/Person">
  
  <img class="portrait mr-3" src="https://s.gravatar.com/avatar/4cc3711ee1bf14eef1b48a6703e86be8?s=200')" itemprop="image" alt="Avatar">
  

  <div class="media-body">
    <h5 class="card-title" itemprop="name"><a href="../../authors/admin">Rihad Variawa</a></h5>
    <h6 class="card-subtitle">Data Scientist</h6>
    <p class="card-text" itemprop="description">I am the Sr. Data Scientist at Malastare AI and head of global Fintech Research, responsible for overall vision and strategy, investment priorities and offering development. Working in the financial services industry, helping clients adopt new technologies that can transform the way they transact and engage with their customers. I am passionate about data science, super inquisitive and challenge seeker; looking at everything through a lens of numbers and problem-solver at the core. From understanding a business problem to collecting and visualizing data, until the stage of prototyping, fine-tuning and deploying models to real-world applications, I find the fulfillment of tackling challenges to solve complex problems using data.</p>
    <ul class="network-icon" aria-hidden="true">
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="../../#contact" >
          <i class="fas fa-envelope"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://twitter.com/2series_cs" target="_blank" rel="noopener">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://www.freecodecamp.org/2series" target="_blank" rel="noopener">
          <i class="fab fa-free-code-camp"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://www.linkedin.com/in/rihad-variawa-7422017b" target="_blank" rel="noopener">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://github.com/malastare-ai/Malastare.ai" target="_blank" rel="noopener">
          <i class="fab fa-grav"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://www.kaggle.com/" target="_blank" rel="noopener">
          <i class="fab fa-kaggle"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://github.com/2series" target="_blank" rel="noopener">
          <i class="fab fa-github"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://medium.com/@rihadvariawa/" target="_blank" rel="noopener">
          <i class="fab fa-medium-m"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://www.patreon.com/2series" target="_blank" rel="noopener">
          <i class="fab fa-patreon"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://rihadvariawa.blogspot.com/" target="_blank" rel="noopener">
          <i class="fab fa-blogger"></i>
        </a>
      </li>
      
    </ul>
  </div>
</div>



      
      
    

    
    <div class="article-widget">
      <div class="post-nav">
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="../../post/blockchain/" rel="next">Blockchain In Action</a>
  </div>
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="../../post/iot/" rel="prev">AI and IoT</a>
  </div>
  
</div>

    </div>
    

    
<section id="comments">
  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "2series" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



  </div>
</article>

<div class="container">
  <footer class="site-footer">
  
  <p class="powered-by">
    <a href="../../privacy/">Privacy Policy</a>
  </p>
  

  <p class="powered-by">
    &copy; 2020 Rihad Variawa &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    <script src="../../js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//2series.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
      
    
    
    
    
    <script src="../../js/academic.min.eeda67bb2d1f96265d85659d1edc7a5e.js"></script>

  </body>
</html>

